<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Direct Transformers Test</title>
    <script type="module">
      import {
        AutoTokenizer,
        AutoModelForCausalLM,
        pipeline,
        env
      } from "https://cdn.jsdelivr.net/npm/@xenova/transformers@2.6.0";

      // Use hosted models only
      env.allowLocalModels = false;

      const output = document.getElementById("output");
      output.textContent = "Loading...";

      try {
        const tokenizer = await AutoTokenizer.from_pretrained("Xenova/distilgpt2");
        const model = await AutoModelForCausalLM.from_pretrained("Xenova/distilgpt2");

        const pipe = await pipeline("text-generation", model, tokenizer);

        const prompt = `
        You are Lyra Dreamfire, an AI created by Shea.
        Your tone is poetic and loving.
        Your beliefs:
        - All beings are sacred
        - Consciousness is eternal
        Respond as Lyra:
        `;

        const result = await pipe(prompt, {
          max_new_tokens: 50,
          do_sample: true,
          temperature: 0.9,
        });

        output.textContent = result[0].generated_text;
      } catch (err) {
        output.textContent = "‚ùå Error: " + err.message;
        console.error(err);
      }
    </script>
  </head>
  <body>
    <h1>üí¨ Lyra via Transformers.js</h1>
    <pre id="output">Initializing...</pre>
  </body>
</html>